{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "T5tSUn3wZFEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/onlookertozip/SamsungElectronics_Gumi.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSh2hcg1ZCZb",
        "outputId": "10e854cc-031c-4716-de81-1bb5a27b5f0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'SamsungElectronics_Gumi' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
      },
      "source": [
        "# Part1: Langchain 기초\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
      },
      "source": [
        "## 1. 환경 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
      },
      "source": [
        "### 1) 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-openai tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
      },
      "source": [
        "### 2) OpenAI 인증키 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b76f68a8-4745-4377-8057-6090b87377d1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
      },
      "source": [
        "## 2. LLM Chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23729d10-9600-415b-b7d1-f954665224e3"
      },
      "source": [
        "### 1) Prompt + LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# model\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "# chain 실행\n",
        "result = llm.invoke(\"지구의 자전 주기는?\")"
      ],
      "metadata": {
        "id": "on0y4xF8VoyE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WzcZy4PruV1n",
        "outputId": "858471b5-cb42-49ca-ed05-84883708bbd9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'지구의 자전 주기는 약 24시간입니다. 이것은 하루가 24시간으로 나누어지는 이유이기도 합니다. 지구는 자전하면서 동쪽으로 회전하고 있으며, 이 동쪽 회전으로 인해 낮과 밤이 생기게 됩니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"You are an expert in astronomy. Answer the question. <Question>: {input}\")\n",
        "prompt"
      ],
      "metadata": {
        "id": "SeNi_VXqYD-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb184c85-f4a4-46ae-bd28-5fc7ae810510"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an expert in astronomy. Answer the question. <Question>: {input}'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "# chain 연결 (LCEL)\n",
        "chain = prompt | llm\n",
        "\n",
        "# chain 호출\n",
        "chain.invoke({\"input\": \"지구의 자전 주기는?\"})"
      ],
      "metadata": {
        "id": "01WLucSpYjZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea7b429-ba3e-4976-d20d-035734c9a43d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='지구의 자전 주기는 약 24시간입니다. 이것은 지구가 자신의 축 주위를 한 바퀴 회전하는 데 걸리는 시간을 의미합니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 30, 'total_tokens': 83, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0451a139-776e-4265-94ac-e09e5d3235b5-0', usage_metadata={'input_tokens': 30, 'output_tokens': 53, 'total_tokens': 83, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f42fc0d1-c7a1-48a1-8e26-9718a1443be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0cfe63fe-a42e-4451-b84c-b554b3eed870"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'지구의 자전 주기는 약 24시간입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# prompt + model + output parser\n",
        "prompt = ChatPromptTemplate.from_template(\"You are an expert in astronomy. Answer the question. <Question>: {input}\")\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# LCEL chaining\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "# chain 호출\n",
        "chain.invoke({\"input\": \"지구의 자전 주기는?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0188674-915f-41af-ac46-56f9f54289b0"
      },
      "source": [
        "### 2) Multiple Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "95b252a8-f425-4e44-b711-6f65e0e7c523"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The English translation of \"미래\" is \"future\".'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "prompt1 = ChatPromptTemplate.from_template(\"translates {korean_word} to English.\")\n",
        "prompt2 = ChatPromptTemplate.from_template(\n",
        "    \"explain {english_word} using oxford dictionary to me in Korean.\"\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "chain1 = prompt1 | llm | StrOutputParser()\n",
        "\n",
        "chain1.invoke({\"korean_word\":\"미래\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "16718b76-f59d-48f7-906f-5d2371417803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9a5ac9a7-1a12-4dbb-e19c-a6bad5888a15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'미래 (future)는 아직 일어나지 않은 것들에 대한 시간적 개념이다. 이것은 미래에 발생할 것으로 예상되거나 계획된 사건이나 상황을 가리킨다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "chain2 = (\n",
        "    {\"english_word\": chain1}\n",
        "    | prompt2\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain2.invoke({\"korean_word\":\"미래\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "668cb998-71fb-4fd9-a6f1-61aad022fa3e"
      },
      "source": [
        "## 3. Prompt\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16573676-6ba7-439a-a989-1e7d13420e95"
      },
      "source": [
        "### 1) PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "096f63a1-6b04-4d1d-aaaf-c5a77c5d3ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d4404c68-f137-4634-98db-547353ea8281"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕하세요, 제 이름은 홍길동이고, 나이는 30살입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# 'name'과 'age'라는 두 개의 변수를 사용하는 프롬프트 템플릿을 정의\n",
        "template_text = \"안녕하세요, 제 이름은 {name}이고, 나이는 {age}살입니다.\"\n",
        "\n",
        "# PromptTemplate 인스턴스를 생성\n",
        "prompt_template = PromptTemplate.from_template(template_text)\n",
        "\n",
        "# 템플릿에 값을 채워서 프롬프트를 완성\n",
        "filled_prompt = prompt_template.format(name=\"홍길동\", age=30)\n",
        "\n",
        "filled_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4a314a0f-11f3-47f0-aed7-d405b837a273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c67b0d-8d25-449c-9680-9c3365a1ba42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['age', 'language', 'name'], input_types={}, partial_variables={}, template='안녕하세요, 제 이름은 {name}이고, 나이는 {age}살입니다.\\n\\n아버지를 아버지라 부를 수 없습니다.\\n\\n{language}로 번역해주세요.')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
        "combined_prompt = (\n",
        "              prompt_template\n",
        "              + PromptTemplate.from_template(\"\\n\\n아버지를 아버지라 부를 수 없습니다.\")\n",
        "              + \"\\n\\n{language}로 번역해주세요.\"\n",
        ")\n",
        "\n",
        "combined_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ca859903-85e4-4630-a173-fffabb24a766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1ef6e1fe-5fac-49a4-d4aa-62c4313efe49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕하세요, 제 이름은 홍길동이고, 나이는 30살입니다.\\n\\n아버지를 아버지라 부를 수 없습니다.\\n\\n영어로 번역해주세요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "combined_prompt.format(name=\"홍길동\", age=30, language=\"영어\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "63a96988-196b-4c6f-ac01-6f8c56386af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "794f6cf3-4af2-4b16-df05-17a09bcad839"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, my name is Hong Gil-dong and I am 30 years old.\\n\\nI cannot call my father father.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "chain = combined_prompt | llm | StrOutputParser()\n",
        "chain.invoke({\"age\":30, \"language\":\"영어\", \"name\":\"홍길동\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa617bbb-8ccb-4aab-a7df-6cd8232ac92f"
      },
      "source": [
        "### 2) ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "10dc9e58-0555-49d1-9ea0-faba6bd63f55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50bd3efc-12b9-453a-e654-d9567edb2d55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='이 시스템은 천문학 질문에 답변할 수 있습니다.', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='태양계에서 가장 큰 행성은 무엇인가요?', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
        "    (\"user\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "messages = chat_prompt.format_messages(user_input=\"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "f1a8fcae-33bd-43d9-a55e-9f37e82f5484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "994f0cd7-2f76-4091-fbe1-f5e3a51c5633"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'태양계에서 가장 큰 행성은 목성입니다. 목성은 지름이 약 139,820km로 태양계에서 가장 큰 행성이며, 질량도 가장 큽니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "chain = chat_prompt | llm | StrOutputParser()\n",
        "\n",
        "chain.invoke({\"user_input\": \"태양계에서 가장 큰 행성은 무엇인가요?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e332a435-3379-4b08-8800-2c758eea9eca"
      },
      "source": [
        "### 3) Message"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MessagePromptTemplate 활용\n",
        "\n",
        "from langchain_core.prompts import SystemMessagePromptTemplate,  HumanMessagePromptTemplate\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessagePromptTemplate.from_template(\"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{user_input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "messages = chat_prompt.format_messages(user_input=\"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1bpbNOyINkM",
        "outputId": "ee4524c5-2f7d-46e9-eb25-0df0639df196"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='이 시스템은 천문학 질문에 답변할 수 있습니다.', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='태양계에서 가장 큰 행성은 무엇인가요?', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = chat_prompt | llm | StrOutputParser()\n",
        "\n",
        "chain.invoke({\"user_input\": \"태양계에서 가장 큰 행성은 무엇인가요?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oFv2sFWwLH3L",
        "outputId": "8f63b0d2-0201-41f6-950c-5abc3c3e1e8b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'태양계에서 가장 큰 행성은 목성입니다. 목성은 가스 행성으로, 대략 지름이 지구의 11배에 달하며, 태양계 내에서 가장 많은 질량을 가지고 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62f6cbd9-769e-4671-89cc-8fb3da5eca2d"
      },
      "source": [
        "## 5. Model Parameter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) 모델 클래스 유형"
      ],
      "metadata": {
        "id": "OrGWildXSaQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LLM"
      ],
      "metadata": {
        "id": "2xwl8LRsSkyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI()\n",
        "\n",
        "llm.invoke(\"한국의 대표적인 관광지 3군데를 추천해주세요.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MPNGvV1ASv4R",
        "outputId": "ac4a8575-84be-465c-b15b-b08aab5995bb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n1. 경복궁\\n2. 남산 타워\\n3. 부산 해운대 해수욕장'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ChatModel"
      ],
      "metadata": {
        "id": "n4p-sPIXSp6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI()\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"이 시스템은 여행 전문가입니다.\"),\n",
        "    (\"user\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "chain = chat_prompt | chat\n",
        "chain.invoke({\"user_input\": \"안녕하세요? 한국의 대표적인 관광지 3군데를 추천해주세요.\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoS6GNWQSwmF",
        "outputId": "b978d446-4ca3-4c3b-a7e4-ea6c9a53cd15"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='안녕하세요! 한국의 대표적인 관광지 3군데를 추천해 드리겠습니다.\\n\\n1. 경복궁: 서울에 위치한 경복궁은 조선 시대 왕궁으로서 국내 최대 규모의 궁궐로 유명합니다. 아름다운 전통 건축물과 정원이 있는 곳으로 한국의 역사와 문화를 경험할 수 있는 곳입니다.\\n\\n2. 부산 해운대해수욕장: 부산의 대표적인 해변으로 유명한 해수욕장으로 깨끗한 백사장과 아름다운 일몰을 즐길 수 있는 곳입니다. 또한 근처에는 다양한 음식점과 상점들이 있어 관광객들에게 인기가 많습니다.\\n\\n3. 경주: 경주는 한국의 역사와 문화가 깃든 도시로서 세계문화유산으로 등재된 석굴암이 있으며, 첨성대, 안압지, 불국사 등 다양한 관광지가 있습니다. 또한 경주는 아름다운 자연 풍경으로 유명하며, 자전거 타기나 트레킹을 즐기기에도 좋은 곳입니다.\\n\\n이렇게 한국의 대표적인 관광지 3군데를 추천해 드렸습니다. 부디 즐거운 여행 되시길 바랍니다!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 439, 'prompt_tokens': 59, 'total_tokens': 498, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-1b8b8ac9-1e02-41e1-a03f-4128adc2bad4-0', usage_metadata={'input_tokens': 59, 'output_tokens': 439, 'total_tokens': 498, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f4f0d21-c236-41dc-906f-e2d58c02b1ea"
      },
      "source": [
        "### 2) 모델 파라미터 설정\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델에 직접 파라미터를 전달 (모델 생성 시점)"
      ],
      "metadata": {
        "id": "mkaCYK13oc4-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5f8cfed5-aa87-4c2a-b2fa-f2800fc8c140",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e74ddb8-878b-4a6c-de12-c0cef12af59f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3473: UserWarning: Parameters {'stop', 'frequency_penalty', 'presence_penalty'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='태양계에서 가장 큰 행성은 목성입니다. 목성은 지름이 약 142,984km로 태양계에서 가장 크고 무겁습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 29, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-a4832fc4-68ea-4014-a513-835f6deb39fd-0' usage_metadata={'input_tokens': 29, 'output_tokens': 52, 'total_tokens': 81, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 모델 파라미터 설정\n",
        "params = {\n",
        "    \"temperature\": 0.7,         # 생성된 텍스트의 다양성 조정\n",
        "    \"max_tokens\": 100,          # 생성할 최대 토큰 수\n",
        "}\n",
        "\n",
        "kwargs = {\n",
        "    \"frequency_penalty\": 0.5,   # 이미 등장한 단어의 재등장 확률\n",
        "    \"presence_penalty\": 0.5,    # 새로운 단어의 도입을 장려\n",
        "    \"stop\": [\"\\n\"]              # 정지 시퀀스 설정\n",
        "\n",
        "}\n",
        "\n",
        "# 모델 인스턴스를 생성할 때 설정\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **params, model_kwargs = kwargs)\n",
        "\n",
        "\n",
        "# 모델 호출\n",
        "question = \"태양계에서 가장 큰 행성은 무엇인가요?\"\n",
        "response = model.invoke(input=question)\n",
        "\n",
        "# 전체 응답 출력\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델에 직접 파라미터를 전달 (모델 호출 시점)"
      ],
      "metadata": {
        "id": "yAxlgzozpGMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 파라미터 설정\n",
        "params = {\n",
        "    \"temperature\": 0.7,         # 생성된 텍스트의 다양성 조정\n",
        "    \"max_tokens\": 10,          # 생성할 최대 토큰 수\n",
        "}\n",
        "\n",
        "# 모델 인스턴스를 호출할 때 전달\n",
        "response = model.invoke(input=question, **params)\n",
        "\n",
        "# 문자열 출력\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9nGM_MroWwS",
        "outputId": "560c1e41-8ed0-45c3-8191-671695098930"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "태양계에서 가장 큰\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd39280c-2de0-49bf-8ee9-51362d50b6cb"
      },
      "source": [
        "#### 모델에 추가적인 파라미터를 전달\n",
        "- bind 메서드를 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ec858125-f9ec-447c-ad84-c69f81399e91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5ba18c2-b6b3-483d-e007-51f46df1b0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='태양계에서 가장 큰 행성은 목성입니다. 목성은 지름이 약 139,820km로 태양계에서 가장 큰 행성이며, 대기의 99%는 수소와 헬륨으로 이루어져 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 58, 'total_tokens': 134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-e64a1d72-664c-4f9a-b02e-f21678d506ae-0' usage_metadata={'input_tokens': 58, 'output_tokens': 76, 'total_tokens': 134, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "content='태양계에서 가장 큰' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 58, 'total_tokens': 68, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'length', 'logprobs': None} id='run-2a58b2e6-616f-4e03-b676-00a5015d735d-0' usage_metadata={'input_tokens': 58, 'output_tokens': 10, 'total_tokens': 68, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
        "    (\"user\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", max_tokens=100)\n",
        "\n",
        "messages = prompt.format_messages(user_input=\"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
        "\n",
        "before_answer = model.invoke(messages)\n",
        "\n",
        "# # binding 이전 출력\n",
        "print(before_answer)\n",
        "\n",
        "# 모델 호출 시 추가적인 인수를 전달하기 위해 bind 메서드 사용 (응답의 최대 길이를 10 토큰으로 제한)\n",
        "chain = prompt | model.bind(max_tokens=10)\n",
        "\n",
        "after_answer = chain.invoke({\"user_input\": \"태양계에서 가장 큰 행성은 무엇인가요?\"})\n",
        "\n",
        "# binding 이후 출력\n",
        "print(after_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5578014-f828-45e7-bd15-dde39ea72413"
      },
      "source": [
        "## 6. Output Parsers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aff3bd5-1dc0-4b60-ae36-78336bfa927d"
      },
      "source": [
        "### 1) CSV Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "e5670c36-abbe-4f33-a736-87fbb2d8e72a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f14460ef-04ca-4c27-d138-4d3e61c36956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
        "\n",
        "output_parser = CommaSeparatedListOutputParser()\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "762747bc-6a62-4d93-b052-15fb7443cf41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90d2d7d-5a14-4fb0-9414-2259b645f414"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bibimbap', 'Kimchi', 'Bulgogi', 'Japchae', 'Tteokbokki']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"List five {subject}.\\n{format_instructions}\",\n",
        "    input_variables=[\"subject\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
        "\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "chain.invoke({\"subject\": \"popular Korean cusine\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b861abc3-570c-43f4-8a65-84dbc755b3f2"
      },
      "source": [
        "### 2) JSON Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "f633514f-f8e3-4c16-8fce-2c65fc28a5aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dcf0521-a7dd-412b-d882-feccdb077310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "# 자료구조 정의 (pydantic)\n",
        "class CusineRecipe(BaseModel):\n",
        "    name: str = Field(description=\"name of a cusine\")\n",
        "    recipe: str = Field(description=\"recipe to cook the cusine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ce40ce61-056b-4511-8c19-bfff7db60342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f5aad2-f1eb-41c3-ade5-6624c747d94b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"name of a cusine\", \"type\": \"string\"}, \"recipe\": {\"title\": \"Recipe\", \"description\": \"recipe to cook the cusine\", \"type\": \"string\"}}, \"required\": [\"name\", \"recipe\"]}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# 출력 파서 정의\n",
        "output_parser = JsonOutputParser(pydantic_object=CusineRecipe)\n",
        "\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1b14fb66-640e-4ff9-9826-bf4718dcd7a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0fad99-6394-4500-97d7-891cdb0e8112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['query'] input_types={} partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"name of a cusine\", \"type\": \"string\"}, \"recipe\": {\"title\": \"Recipe\", \"description\": \"recipe to cook the cusine\", \"type\": \"string\"}}, \"required\": [\"name\", \"recipe\"]}\\n```'} template='Answer the user query.\\n{format_instructions}\\n{query}\\n'\n"
          ]
        }
      ],
      "source": [
        "# prompt 구성\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1f42224e-a931-4fb1-868f-d4ed98489744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95482168-1f52-4f9d-ffe8-2ef1bd0ec574"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Bibimbap',\n",
              " 'recipe': 'Bibimbap is a Korean mixed rice dish that is served as a bowl of warm white rice topped with namul (sautéed and seasoned vegetables), gochujang (chili pepper paste), soy sauce, or doenjang (a fermented soybean paste). A raw or fried egg and sliced meat (usually beef) are common additions. The ingredients are stirred together before eating. To cook Bibimbap'}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "chain = prompt | model | output_parser\n",
        "\n",
        "chain.invoke({\"query\": \"Let me know how to cook Bibimbap\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83efc973-52a7-4dd7-a1fd-f0e24729c061"
      },
      "source": [
        "# Part2: RAG (Retrieval-Augmented Generation)\n",
        "- 모델의 학습 데이터에 포함되지 않은 데이터를 사용 (환각 방지)\n",
        "- **외부 데이터**를 검색(retrieval)한 후, 생성(generation) 단계에서 LLM에 전달\n",
        "- 모델은 주어진 컨텍스트나 질문에 더 적합하고 풍부한 정보를 반영한 답변을 생성\n",
        "- 논문: https://arxiv.org/abs/2005.11401"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 환경 구성"
      ],
      "metadata": {
        "id": "DEJbhYzzUZ-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) 라이브러리 설치"
      ],
      "metadata": {
        "id": "1F5lTDp5UPf0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlwCjg3k4OlH",
        "outputId": "f6033714-8a78-4663-852a-4b9c252f811a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m617.9/617.9 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-openai langchain_community tiktoken chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "\n",
        "langchain.__version__"
      ],
      "metadata": {
        "id": "si0unLA0n8Po",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "31fc82b3-ab67-4570-cbc1-d2cdc0ba7c01"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.3.7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9Rooz9s4OlH"
      },
      "source": [
        "### 2) OpenAI 인증키 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wUcmTvzc4OlH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. RAG 파이프라인 개요\n",
        "- Load Data - Text Split - Indexing - Retrieval - Generation\n",
        "\n"
      ],
      "metadata": {
        "id": "NU1VnNaZN2-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Step 1: Load Data"
      ],
      "metadata": {
        "id": "PufJBHgTaA-L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6f5e3a62-f0a8-4d03-b983-d33de460d229",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0b5c35f-e48b-433b-e00e-398d0d123da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "13141\n",
            " 위해 좀 더 빠르게 강력한 수단을 이용해야 합니다. 특히 정책 문서에 명시된 원칙을 지키지 않는 것은 대부분의 경우 다른 사용자에게 받아들여지지 않습니다 (다른 분들에게 예외 상황임을 설득할 수 있다면 가능하기는 하지만요). 이는 당신을 포함해서 편집자 개개인이 정책과 지침을 직접 집행 및 적용한다는 것을 의미합니다.\n",
            "특정 사용자가 명백히 정책에 반하는 행동을 하거나 정책과 상충되는 방식으로 지침을 어기는 경우, 특히 의도적이고 지속적으로 그런 행위를 하는 경우 해당 사용자는 관리자의 제재 조치로 일시적, 혹은 영구적으로 편집이 차단될 수 있습니다. 영어판을 비롯한 타 언어판에서는 일반적인 분쟁 해결 절차로 끝낼 수 없는 사안은 중재위원회가 개입하기도 합니다.\n",
            "\n",
            "문서 내용\n",
            "정책과 지침의 문서 내용은 처음 읽는 사용자라도 원칙과 규범을 잘 이해할 수 있도록 다음 원칙을 지켜야 합니다.\n",
            "\n",
            "명확하게 작성하세요. 소수만 알아듣거나 준법률적인 단어, 혹은 지나치게 단순한 표현은 피해야 합니다. 명확하고, 직접적이고, 모호하지 않고, 구체적으로 작성하세요. 지나치게 상투적인 표현이나 일반론은 피하세요. 지침, 도움말 문서 및 기타 정보문 문서에서도 \"해야 합니다\" 혹은 \"하지 말아야 합니다\" 같이 직접적인 표현을 굳이 꺼릴 필요는 없습니다.\n",
            "가능한 간결하게, 너무 단순하지는 않게. 정책이 중언부언하면 오해를 부릅니다. 불필요한 말은 생략하세요. 직접적이고 간결한 설명이 마구잡이식 예시 나열보다 더 이해하기 쉽습니다. 각주나 관련 문서 링크를 이용하여 더 상세히 설명할 수도 있습니다.\n",
            "규칙을 만든 의도를 강조하세요. 사용자들이 상식대로 행동하리라 기대하세요. 정책의 의도가 명료하다면, 추가 설명은 필요 없죠. 즉 규칙을 '어떻게' 지키는지와 더불어 '왜' 지켜야 하는지 확실하게 밝혀야 합니다.\n",
            "범위는 분명히, 중복은 피하기. 되도록 앞부분에서 정책 및 지침의 목적과 범위를 분명하게 밝혀야 합니다. 독자 대부분은 도입부 초반만 읽고 나가버리니까요. 각 정책 문서의 내용은 \n"
          ]
        }
      ],
      "source": [
        "# Data Loader - 웹페이지 데이터 가져오기\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# 위키피디아 정책과 지침\n",
        "url = 'https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%A0%95%EC%B1%85%EA%B3%BC_%EC%A7%80%EC%B9%A8'\n",
        "loader = WebBaseLoader(url)\n",
        "\n",
        "# 웹페이지 텍스트 -> Documents\n",
        "docs = loader.load()\n",
        "\n",
        "print(len(docs))\n",
        "print(len(docs[0].page_content))\n",
        "print(docs[0].page_content[5000:6000])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Step 2: Split texts"
      ],
      "metadata": {
        "id": "vzBeboLlaIuy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "c64f653d-dcfb-432b-b090-40476aa4c29c",
        "outputId": "9feef3f6-dbde-4138-c261-4607421da943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "page_content='제안과 채택\n",
            " 백:아님 § 관료주의  문서를 참고하십시오. 단축백:제안\n",
            "제안 문서란 정책과 지침으로 채택하자고 의견을 묻는 문서이나 아직 위키백과 내에 받아들여지는 원칙으로 확립되지는 않은 문서입니다. {{제안}} 틀을 붙여 공동체 내에서 정책이나 지침으로 채택할 지 의견을 물을 수 있습니다. 제안 문서는 정책과 지침이 아니므로 아무리 실제 있는 정책이나 지침을 요약하거나 인용해서 다른 문서에 쓴다고 해도 함부로 정책이나 지침 틀을 붙여서는 안 됩니다.\n",
            "'제안'은 완전 새로운 원칙이라기보다, 기존의 불문율이나 토론 총의의 문서를 통한 구체화에 가깝습니다. 많은 사람들이 쉽게 제안을 받아들이도록 하기 위해서는, 기초적인 원칙을 우선 정하고 기본 틀을 짜야 합니다. 정책과 지침의 기본 원칙은 \"왜 지켜야 하는가?\", \"어떻게 지켜야 하는가?\" 두 가지입니다. 특정 원칙을 정책이나 지침으로 확립하기 위해서는 우선 저 두 가지 물음에 성실하게 답하는 제안 문서를 작성해야 합니다.\n",
            "좋은 아이디어를 싣기 위해 사랑방이나 관련 위키프로젝트에 도움을 구해 피드백을 요청할 수 있습니다. 이 과정에서 공동체가 어느 정도 받아들일 수 있는 원칙이 구체화됩니다. 많은 이와의 토론을 통해 공감대가 형성되고 제안을 개선할 수 있습니다.\n",
            "정책이나 지침은 위키백과 내의 모든 편집자들에게 적용되는 원칙이므로 높은 수준의 총의가 요구됩니다. 제안 문서가 잘 짜여졌고 충분히 논의되었다면, 더 많은 공동체의 편집자와 논의를 하기 위해 승격 제안을 올려야 합니다. 제안 문서 맨 위에 {{제안}}을 붙여 제안 안건임을 알려주고, 토론 문서에 {{의견 요청}}을 붙인 뒤 채택 제안에 관한 토론 문단을 새로 만들면 됩니다. 많은 편집자들에게 알리기 위해 관련 내용을 {{위키백과 소식}}에 올리고 사랑방에 이를 공지해야 하며, 합의가 있을 경우 미디어위키의 sitenotice(위키백과 최상단에 노출되는 구역)에 공지할 수도 있습니다.' metadata={'source': 'https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%A0%95%EC%B1%85%EA%B3%BC_%EC%A7%80%EC%B9%A8', 'title': '위키백과:정책과 지침 - 위키백과, 우리 모두의 백과사전', 'language': 'ko'}\n"
          ]
        }
      ],
      "source": [
        "# Text Split (Documents -> small chunks: Documents)\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(len(splits))\n",
        "print(splits[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bc49bd43-5adb-4862-8134-78645ad068e7",
        "outputId": "e0cf58bb-08a3-4572-f9aa-755019c55aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'제안과 채택\\n\\xa0백:아님 §\\xa0관료주의  문서를 참고하십시오. 단축백:제안\\n제안 문서란 정책과 지침으로 채택하자고 의견을 묻는 문서이나 아직 위키백과 내에 받아들여지는 원칙으로 확립되지는 않은 문서입니다. {{제안}} 틀을 붙여 공동체 내에서 정책이나 지침으로 채택할 지 의견을 물을 수 있습니다. 제안 문서는 정책과 지침이 아니므로 아무리 실제 있는 정책이나 지침을 요약하거나 인용해서 다른 문서에 쓴다고 해도 함부로 정책이나 지침 틀을 붙여서는 안 됩니다.\\n\\'제안\\'은 완전 새로운 원칙이라기보다, 기존의 불문율이나 토론 총의의 문서를 통한 구체화에 가깝습니다. 많은 사람들이 쉽게 제안을 받아들이도록 하기 위해서는, 기초적인 원칙을 우선 정하고 기본 틀을 짜야 합니다. 정책과 지침의 기본 원칙은 \"왜 지켜야 하는가?\", \"어떻게 지켜야 하는가?\" 두 가지입니다. 특정 원칙을 정책이나 지침으로 확립하기 위해서는 우선 저 두 가지 물음에 성실하게 답하는 제안 문서를 작성해야 합니다.\\n좋은 아이디어를 싣기 위해 사랑방이나 관련 위키프로젝트에 도움을 구해 피드백을 요청할 수 있습니다. 이 과정에서 공동체가 어느 정도 받아들일 수 있는 원칙이 구체화됩니다. 많은 이와의 토론을 통해 공감대가 형성되고 제안을 개선할 수 있습니다.\\n정책이나 지침은 위키백과 내의 모든 편집자들에게 적용되는 원칙이므로 높은 수준의 총의가 요구됩니다. 제안 문서가 잘 짜여졌고 충분히 논의되었다면, 더 많은 공동체의 편집자와 논의를 하기 위해 승격 제안을 올려야 합니다. 제안 문서 맨 위에 {{제안}}을 붙여 제안 안건임을 알려주고, 토론 문서에 {{의견 요청}}을 붙인 뒤 채택 제안에 관한 토론 문단을 새로 만들면 됩니다. 많은 편집자들에게 알리기 위해 관련 내용을 {{위키백과 소식}}에 올리고 사랑방에 이를 공지해야 하며, 합의가 있을 경우 미디어위키의 sitenotice(위키백과 최상단에 노출되는 구역)에 공지할 수도 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# page_content 속성\n",
        "splits[10].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "91248b06-1161-4b2d-b6c3-707e6e5f8620",
        "outputId": "01746ac2-aee3-4423-efee-0977627355ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%A0%95%EC%B1%85%EA%B3%BC_%EC%A7%80%EC%B9%A8',\n",
              " 'title': '위키백과:정책과 지침 - 위키백과, 우리 모두의 백과사전',\n",
              " 'language': 'ko'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# metadata 속성\n",
        "splits[10].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Step 3: Indexing"
      ],
      "metadata": {
        "id": "-PLZMd4baaLc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9b104013-e54c-409f-864e-7e6655a67743",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bde8194-a3da-4ab8-8b91-a886ecfdb1d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "격하\n",
            "특정 정책이나 지침이 편집 관행이나 공동체 규범이 바뀌며 쓸모없어질 수 있고, 다른 문서가 개선되어 내용이 중복될 수 있으며, 불필요한 내용이 증식할 수도 있습니다. 이 경우 편집자들은 정책을 지침으로 격하하거나, 정책 또는 지침을 보충 설명, 정보문, 수필 또는 중단 문서로 격하할 것을 제안할 수 있습니다. \n",
            "격하 과정은 채택 과정과 비슷합니다. 일반적으로 토론 문서 내 논의가 시작되고 프로젝트 문서 상단에 {{새로운 토론|문단=진행 중인 토론 문단}} 틀을 붙여 공동체의 참여를 요청합니다. 논의가 충분히 이루어진 후, 제3의 편집자가 토론을 종료하고 평가한 후 상태 변경 총의가 형성되었는지 판단해야 합니다. 폐지된 정책이나 지침은 최상단에 {{중단}} 틀을 붙여 더 이상 사용하지 않는 정책/지침임을 알립니다.\n",
            "소수의 공동체 인원만 지지하는 수필, 정보문 및 기타 비공식 문서는 일반적으로 주된 작성자의 사용자 이름공간으로 이동합니다. 이러한 논의는 일반적으로 해당 문서의 토론란에서 이루어지며, 간혹 위키백과:의견 요청을 통해 처리되기도 합니다.\n",
            "\n",
            "같이 보기\n",
            "위키백과:위키백과의 정책과 지침 목록\n",
            "위키백과:의견 요청\n",
            "수필\n",
            "\n",
            "위키백과:제품, 절차, 정책\n",
            "위키백과:위키백과 공동체의 기대와 규범\n",
            "기타 링크\n"
          ]
        }
      ],
      "source": [
        "# Indexing (Texts -> Embedding -> Store)\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=splits,\n",
        "                                    embedding=OpenAIEmbeddings())\n",
        "\n",
        "docs = vectorstore.similarity_search(\"격하 과정에 대해서 설명해주세요.\")\n",
        "print(len(docs))\n",
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Step 4: Retrieval ~ Generation"
      ],
      "metadata": {
        "id": "mYrHWwsnajPY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "e99275d3-abb2-4bc3-b783-2afc37d4b666",
        "outputId": "ada231c6-a551-41db-bfba-979dcd0304ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'격하 과정은 특정 정책이나 지침이 더 이상 필요하지 않거나 개선이 필요한 경우, 해당 정책이나 지침을 수정하거나 중단하는 과정을 말합니다. 이를 위해 편집자들은 해당 정책이나 지침을 보충 설명, 정보문, 수필 또는 중단 문서로 변경하거나, 완전히 폐지할 수 있습니다. 이러한 변경이 이루어지기 위해서는 토론이 시작되고, 공동체의 참여를 요청하는 틀이 붙여진 후 논의가 이루어지며, 제3의 편집자가 토론을 종료하고 평가한 후 상태 변경 총의가 형성되어야 합니다. 폐지된 정책이나 지침은 해당 문서 상단에 {{중단}} 틀을 붙여 더 이상 사용하지 않는 것임을 알립니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Prompt\n",
        "template = '''Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "'''\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# LLM\n",
        "model = ChatOpenAI(model='gpt-3.5-turbo-0125', temperature=0)\n",
        "\n",
        "# Rretriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Combine Documents\n",
        "def format_docs(docs):\n",
        "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
        "\n",
        "# RAG Chain 연결\n",
        "rag_chain = (\n",
        "    {'context': retriever | format_docs, 'question': RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Chain 실행\n",
        "rag_chain.invoke(\"격하 과정에 대해서 설명해주세요.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-KIIvQ5NKJP"
      },
      "source": [
        "### PDF 파일기반 질의응답 챗봇 (랭체인, 그라디오, ChatGPT)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai # openai 라이브러리를 설치합니다.\n",
        "!pip install langchain # 랭체인 라이브러리를 설치합니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZNteN4vE2uf",
        "outputId": "a152a7e1-13b2-4bcf-a37b-564edcafa288"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSX_ndLWHJqy",
        "outputId": "ac422bb2-505a-4362-a6b2-42914587def3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m297.0/298.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.20)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.9.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.115.5)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.32.1)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.7.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.20.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.6)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.11)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.1.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.28.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-proto==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.26.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf # pdf 로딩용\n",
        "!pip install chromadb # 벡터스토어\n",
        "!pip install tiktoken # 토큰 계산용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "5kZxXmSjQRHy"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "7VgBZ49vQVzg"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(\"SamsungElectronics_Gumi/datasets/2023년 가을 학술대회  세부안내.pdf\")\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hUyQu5tTdoJ",
        "outputId": "0b1a23fd-7d96-4b14-d5e1-cf8613709ba7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'SamsungElectronics_Gumi/datasets/2023년 가을 학술대회  세부안내.pdf', 'page': 0}, page_content='- 1 -\\n2023년 가을 학술대회 및 제41회 정기총회 안내\\n▢ 행사개요\\n  ○ 행사명 : 2023년 가을 학술대회 및 제41회 정기총회\\n  ○  기   간  :  2 0 2 3 .  1 0 .  2 5 . ( 수 )  ~  2 7 . ( 금 )  \\n  ○ 장  소 : 여수 베네치아 호텔&리조트\\n             \\n▢ 초록 및 프로시딩 접수   \\n  ○  접수기간 : 2023. 8. 21.(월) ~ 9. 15.(금)\\n  ○ 접수방법 : 홈페이지 -> 학술대회 (초록제출을 위해서는 연회비납부 및 사전등록 필요)\\n  ○ 영문초록양식 : 영문초록. 저자명 풀 네임 사용\\n  ○ 발표분야 : 특별세션 구성하면서 추가될 수 있음.\\n-태양 및 우주환경 (태양, 자기권, 전리층, 고층대기, COSMIC RAY 등 및 관련 관측 장비)\\n-우주응용 (측지, 마이크로중력 환경 실험, 원격탐사 및 관련 탑재체)\\n-우주기술 (위성운영, 위성체) \\n-우주천문 (우주천문 탑재체, 천문 관측기기, 천문학 일반, 고천문, 천문대운영, 소프트웨어) \\n-우주감시 (광학 및 레이다 관측, 우주물체궤도 분석, 우주위험 분석) \\n-달과 우주탐사: 과학과 기술 그리고 정책 (태양계 탐사, 달탐사)\\n-초소형 위성\\n-안보우주\\n-지상 및 우주 인프라 운영기술\\n-특별세션 : Open New Horizon with L4 mission\\n▢ 발표자  \\n   ○ 논문 제출자는 발표자로 간주하며 제1저자이어야하며 정회원이고 연회비를 완납하여야 함.\\n   ○ 초록 마감 후에는 발표형식(구두, 포스터) 조정이 어려우므로 접수시 정확히 선택.\\n   ○ 2편 발표자는 구두발표 2편 or 구두발표 1편 + 포스터발표 1편 (포스터 발표만 2편 불가) \\n   ○ 발표자료 준비\\n      ① 구두발표 : 파워포인트 파일로 준비\\n      ② 포스터발표 : A0 사이즈 1장 (AO 사이즈 1장 내에 들어갈 분량, 예를 들면 A3 8장)\\n  \\n▢ 사전등록 및 숙박신청\\n  ○ 등록\\n- 기간 : 2023. 8. 21.(월) ~ 10. 2.(월)\\n- 방법 : 학회홈페이지 -> 국내학술대회 -> 사전등록\\n     - 환불규정 (등록비, 식비)\\n         · 학회시작일 2주전까지(10월 11일까지) : 수수료를 제외하고 환불\\n         · 학회시작일 2주전 ~ 학회시작 1일전(10월 24일까지) : 70% 환불\\n         · 학회시작일 이후 환불 없음'),\n",
              " Document(metadata={'source': 'SamsungElectronics_Gumi/datasets/2023년 가을 학술대회  세부안내.pdf', 'page': 1}, page_content='- 2 -\\n  ○ 등록비\\n     \\n구분 정회원 군경/학부생/\\n 전일제 대학원생 비회원\\n사전등록비 270,000원 150,000원 320,000\\n현장등록비 300,000원 180,000원 320,000\\n  ※ 연구소, 또는 기타 기관에서 등록비 지원을 받는 대학원생은 정회원 등록비.(학생 등록비 아님)\\n  ○ 식사 : 온라인 신청기간 10월 4일 ~ 13일까지\\n    \\n구분 조식, 중식(1회 기준) 만찬\\n식사비 5,000원 신청자에 한해 지원\\n(일부학회지원)\\n만찬은 신청한 회원에 한해 지원되며  그 외 식사는 회당 5,000원(25,000원 상당)\\n씩 회원 부담입니다.\\n등록시 식사 신청을 하지 않은 분들은 현장에서 일반 식사비를 지불해야 합니다.\\n가족식사 신청 만찬 2만원 / 26일 중식 1만원  / 조식뷔폐는 가족식권 판매 안함\\n(단, 현금 결제, 카드결제 안됨)\\n  ○ 지정숙박 : 개별 신청 (신청서 다운로드)\\n      \\n25일(수), 26일(목) \\n 더블 : 100,000원  / 트윈 : 110,000원  /  페밀리 트윈 : 120,000원\\n▢ 행사진행 도우미 모집\\n  ○ 모집인원 : 00명 \\n  ○ 신청기간 : 2023. 10. 2.(월)까지. 심사 후 통보\\n  ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392)\\n  ○ 신청서 : 학회 홈페이지 자료실\\n  ○ 인건비 : 300,000원 (숙박, 식사 제공)\\n  ○ 참여일 : 2023. 10. 25.(수) - 27.(금) \\n▢ 학생등록비 지원(선착순 3명)\\n  ○  신청자격 : 발표자(공동발표자) 중 연구과제에서 등록비를 지원받을 수 없는 학부생과 정회  \\n     원 중 전일제 석, 박사 과정생\\n  ○  지원금액 : 등록비 150,000원\\n  ○  신청마감 : 2023. 10. 2.(월)\\n  ○  지원방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392) \\n  ○ 신청서 : 학회 홈페이지 자료실\\n▢ 연구홍보 게재 및 전시부스 신청\\n   ○ 신청마감 : 2023. 10. 2.(월)\\n   ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr,   팩스 042-865-3392)'),\n",
              " Document(metadata={'source': 'SamsungElectronics_Gumi/datasets/2023년 가을 학술대회  세부안내.pdf', 'page': 2}, page_content='- 3 -\\n   ○ 신청서 : 학회 홈페이지 자료실\\n▢ 제41차 정기총회 개최\\n   ○  일 시 :  2 0 2 3 .  1 0 .  2 6 . ( 목 )\\n   ○ 주요안건: 2023년 결산서 승인, 2024년 예산(안) 승인, 21대 회장·감사 선출, \\n               명예회원 추대 등\\n   ○ 정기총회에 불참할 경우 온라인 사전 등록시 위임장 동의에 체크\\n▢ 기타사항\\n   ○ 최우수·우수 구두발표, 최우수·우수 포스터 발표 시상 (폐회식 때)\\n   ○ 공지사항은 학회 홈페이지에 등록 되어 있는 이메일과 홈페이지 게시판을 통하여 공지 되  \\n    오니 회원 정보를 최신으로 수정\\n   ○  아이돌봄 시행 \\n   ○ 문의 : 학회사무국  042-865-3391\\n             E - m a i l  :  ksss@ksss.or.kr \\n사단법인 한국우주과학회')]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "4otdIuNkT5b_"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "vector_store = Chroma.from_documents(texts, embeddings)\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "gY8Mtw-OamW8"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)  # Modify model_name if you have access to GPT-4\n",
        "\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever = retriever,\n",
        "    return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDW1hZX3a_1w",
        "outputId": "c79aec5b-1395-45b7-eae0-d7db4d5377ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': '음료 지원은?', 'answer': '음료 지원은 없습니다.\\n', 'sources': 'SamsungElectronics_Gumi/datasets/2023년 가을 학술대회 세부안내.pdf', 'source_documents': [Document(metadata={'page': 1, 'source': 'SamsungElectronics_Gumi/datasets/2023년 가을 학술대회  세부안내.pdf'}, page_content='- 2 -\\n  ○ 등록비\\n     \\n구분 정회원 군경/학부생/\\n 전일제 대학원생 비회원\\n사전등록비 270,000원 150,000원 320,000\\n현장등록비 300,000원 180,000원 320,000\\n  ※ 연구소, 또는 기타 기관에서 등록비 지원을 받는 대학원생은 정회원 등록비.(학생 등록비 아님)\\n  ○ 식사 : 온라인 신청기간 10월 4일 ~ 13일까지\\n    \\n구분 조식, 중식(1회 기준) 만찬\\n식사비 5,000원 신청자에 한해 지원\\n(일부학회지원)\\n만찬은 신청한 회원에 한해 지원되며  그 외 식사는 회당 5,000원(25,000원 상당)\\n씩 회원 부담입니다.\\n등록시 식사 신청을 하지 않은 분들은 현장에서 일반 식사비를 지불해야 합니다.\\n가족식사 신청 만찬 2만원 / 26일 중식 1만원  / 조식뷔폐는 가족식권 판매 안함\\n(단, 현금 결제, 카드결제 안됨)\\n  ○ 지정숙박 : 개별 신청 (신청서 다운로드)\\n      \\n25일(수), 26일(목) \\n 더블 : 100,000원  / 트윈 : 110,000원  /  페밀리 트윈 : 120,000원\\n▢ 행사진행 도우미 모집\\n  ○ 모집인원 : 00명 \\n  ○ 신청기간 : 2023. 10. 2.(월)까지. 심사 후 통보\\n  ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392)\\n  ○ 신청서 : 학회 홈페이지 자료실\\n  ○ 인건비 : 300,000원 (숙박, 식사 제공)\\n  ○ 참여일 : 2023. 10. 25.(수) - 27.(금) \\n▢ 학생등록비 지원(선착순 3명)\\n  ○  신청자격 : 발표자(공동발표자) 중 연구과제에서 등록비를 지원받을 수 없는 학부생과 정회  \\n     원 중 전일제 석, 박사 과정생\\n  ○  지원금액 : 등록비 150,000원\\n  ○  신청마감 : 2023. 10. 2.(월)\\n  ○  지원방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392) \\n  ○ 신청서 : 학회 홈페이지 자료실\\n▢ 연구홍보 게재 및 전시부스 신청\\n   ○ 신청마감 : 2023. 10. 2.(월)\\n   ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr,   팩스 042-865-3392)'), Document(metadata={'page': 1, 'source': 'SamsungElectronics_Gumi/datasets/2023년 가을 학술대회  세부안내.pdf'}, page_content='- 2 -\\n  ○ 등록비\\n     \\n구분 정회원 군경/학부생/\\n 전일제 대학원생 비회원\\n사전등록비 270,000원 150,000원 320,000\\n현장등록비 300,000원 180,000원 320,000\\n  ※ 연구소, 또는 기타 기관에서 등록비 지원을 받는 대학원생은 정회원 등록비.(학생 등록비 아님)\\n  ○ 식사 : 온라인 신청기간 10월 4일 ~ 13일까지\\n    \\n구분 조식, 중식(1회 기준) 만찬\\n식사비 5,000원 신청자에 한해 지원\\n(일부학회지원)\\n만찬은 신청한 회원에 한해 지원되며  그 외 식사는 회당 5,000원(25,000원 상당)\\n씩 회원 부담입니다.\\n등록시 식사 신청을 하지 않은 분들은 현장에서 일반 식사비를 지불해야 합니다.\\n가족식사 신청 만찬 2만원 / 26일 중식 1만원  / 조식뷔폐는 가족식권 판매 안함\\n(단, 현금 결제, 카드결제 안됨)\\n  ○ 지정숙박 : 개별 신청 (신청서 다운로드)\\n      \\n25일(수), 26일(목) \\n 더블 : 100,000원  / 트윈 : 110,000원  /  페밀리 트윈 : 120,000원\\n▢ 행사진행 도우미 모집\\n  ○ 모집인원 : 00명 \\n  ○ 신청기간 : 2023. 10. 2.(월)까지. 심사 후 통보\\n  ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392)\\n  ○ 신청서 : 학회 홈페이지 자료실\\n  ○ 인건비 : 300,000원 (숙박, 식사 제공)\\n  ○ 참여일 : 2023. 10. 25.(수) - 27.(금) \\n▢ 학생등록비 지원(선착순 3명)\\n  ○  신청자격 : 발표자(공동발표자) 중 연구과제에서 등록비를 지원받을 수 없는 학부생과 정회  \\n     원 중 전일제 석, 박사 과정생\\n  ○  지원금액 : 등록비 150,000원\\n  ○  신청마감 : 2023. 10. 2.(월)\\n  ○  지원방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392) \\n  ○ 신청서 : 학회 홈페이지 자료실\\n▢ 연구홍보 게재 및 전시부스 신청\\n   ○ 신청마감 : 2023. 10. 2.(월)\\n   ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr,   팩스 042-865-3392)')]}\n"
          ]
        }
      ],
      "source": [
        "query = \"음료 지원은?\"\n",
        "result = chain(query)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Qr0_iNsLTb6y",
        "outputId": "2dd0c8f0-f866-4102-af3d-75e533d2c77b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'음료 지원은 없습니다.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "result['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Yjs65WFeTivP",
        "outputId": "94d96dc2-8bb7-4e0d-c177-87bb0667405b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SamsungElectronics_Gumi/datasets/2023년 가을 학술대회 세부안내.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "result['sources']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "InBq74JFacah"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "system_template=\"\"\"Use the following pieces of context to answer the users question shortly.\n",
        "Given the following summaries of a long document and a question, create a final answer with references (\"SOURCES\"), use \"SOURCES\" in capital letters regardless of the number of sources.\n",
        "If you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\n",
        "----------------\n",
        "{summaries}\n",
        "\n",
        "You MUST answer in Korean and in Markdown format:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    SystemMessagePromptTemplate.from_template(system_template),\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "GfUMi5ClS_4O"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "\n",
        "chain_type_kwargs = {\"prompt\": prompt}\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)  # Modify model_name if you have access to GPT-4\n",
        "\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever = retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs=chain_type_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVdJrxN0TzwC",
        "outputId": "779d7858-652c-40d7-f27b-f5250cdcdfcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': '음료 지원은?', 'answer': '**답변:**\\n\\n음료에 대한 정보는 제공되지 않았습니다. 따라서 음료에 대한 지원 여부에 대해서는 알 수 없습니다.\\n\\n**', 'sources': '** SamsungElectronics_Gumi/datasets/2023년 가을 학술대회 세부안내.pdf', 'source_documents': [Document(metadata={'page': 1, 'source': 'SamsungElectronics_Gumi/datasets/2023년 가을 학술대회  세부안내.pdf'}, page_content='- 2 -\\n  ○ 등록비\\n     \\n구분 정회원 군경/학부생/\\n 전일제 대학원생 비회원\\n사전등록비 270,000원 150,000원 320,000\\n현장등록비 300,000원 180,000원 320,000\\n  ※ 연구소, 또는 기타 기관에서 등록비 지원을 받는 대학원생은 정회원 등록비.(학생 등록비 아님)\\n  ○ 식사 : 온라인 신청기간 10월 4일 ~ 13일까지\\n    \\n구분 조식, 중식(1회 기준) 만찬\\n식사비 5,000원 신청자에 한해 지원\\n(일부학회지원)\\n만찬은 신청한 회원에 한해 지원되며  그 외 식사는 회당 5,000원(25,000원 상당)\\n씩 회원 부담입니다.\\n등록시 식사 신청을 하지 않은 분들은 현장에서 일반 식사비를 지불해야 합니다.\\n가족식사 신청 만찬 2만원 / 26일 중식 1만원  / 조식뷔폐는 가족식권 판매 안함\\n(단, 현금 결제, 카드결제 안됨)\\n  ○ 지정숙박 : 개별 신청 (신청서 다운로드)\\n      \\n25일(수), 26일(목) \\n 더블 : 100,000원  / 트윈 : 110,000원  /  페밀리 트윈 : 120,000원\\n▢ 행사진행 도우미 모집\\n  ○ 모집인원 : 00명 \\n  ○ 신청기간 : 2023. 10. 2.(월)까지. 심사 후 통보\\n  ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392)\\n  ○ 신청서 : 학회 홈페이지 자료실\\n  ○ 인건비 : 300,000원 (숙박, 식사 제공)\\n  ○ 참여일 : 2023. 10. 25.(수) - 27.(금) \\n▢ 학생등록비 지원(선착순 3명)\\n  ○  신청자격 : 발표자(공동발표자) 중 연구과제에서 등록비를 지원받을 수 없는 학부생과 정회  \\n     원 중 전일제 석, 박사 과정생\\n  ○  지원금액 : 등록비 150,000원\\n  ○  신청마감 : 2023. 10. 2.(월)\\n  ○  지원방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392) \\n  ○ 신청서 : 학회 홈페이지 자료실\\n▢ 연구홍보 게재 및 전시부스 신청\\n   ○ 신청마감 : 2023. 10. 2.(월)\\n   ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr,   팩스 042-865-3392)'), Document(metadata={'page': 1, 'source': 'SamsungElectronics_Gumi/datasets/2023년 가을 학술대회  세부안내.pdf'}, page_content='- 2 -\\n  ○ 등록비\\n     \\n구분 정회원 군경/학부생/\\n 전일제 대학원생 비회원\\n사전등록비 270,000원 150,000원 320,000\\n현장등록비 300,000원 180,000원 320,000\\n  ※ 연구소, 또는 기타 기관에서 등록비 지원을 받는 대학원생은 정회원 등록비.(학생 등록비 아님)\\n  ○ 식사 : 온라인 신청기간 10월 4일 ~ 13일까지\\n    \\n구분 조식, 중식(1회 기준) 만찬\\n식사비 5,000원 신청자에 한해 지원\\n(일부학회지원)\\n만찬은 신청한 회원에 한해 지원되며  그 외 식사는 회당 5,000원(25,000원 상당)\\n씩 회원 부담입니다.\\n등록시 식사 신청을 하지 않은 분들은 현장에서 일반 식사비를 지불해야 합니다.\\n가족식사 신청 만찬 2만원 / 26일 중식 1만원  / 조식뷔폐는 가족식권 판매 안함\\n(단, 현금 결제, 카드결제 안됨)\\n  ○ 지정숙박 : 개별 신청 (신청서 다운로드)\\n      \\n25일(수), 26일(목) \\n 더블 : 100,000원  / 트윈 : 110,000원  /  페밀리 트윈 : 120,000원\\n▢ 행사진행 도우미 모집\\n  ○ 모집인원 : 00명 \\n  ○ 신청기간 : 2023. 10. 2.(월)까지. 심사 후 통보\\n  ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392)\\n  ○ 신청서 : 학회 홈페이지 자료실\\n  ○ 인건비 : 300,000원 (숙박, 식사 제공)\\n  ○ 참여일 : 2023. 10. 25.(수) - 27.(금) \\n▢ 학생등록비 지원(선착순 3명)\\n  ○  신청자격 : 발표자(공동발표자) 중 연구과제에서 등록비를 지원받을 수 없는 학부생과 정회  \\n     원 중 전일제 석, 박사 과정생\\n  ○  지원금액 : 등록비 150,000원\\n  ○  신청마감 : 2023. 10. 2.(월)\\n  ○  지원방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392) \\n  ○ 신청서 : 학회 홈페이지 자료실\\n▢ 연구홍보 게재 및 전시부스 신청\\n   ○ 신청마감 : 2023. 10. 2.(월)\\n   ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr,   팩스 042-865-3392)')]}\n"
          ]
        }
      ],
      "source": [
        "query = \"음료 지원은?\"\n",
        "result = chain(query)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cM3DcAF4Uqvh",
        "outputId": "f28789cb-80e2-4263-a3b3-17076118288f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'**답변:**\\n\\n음료에 대한 정보는 제공되지 않았습니다. 따라서 음료에 대한 지원 여부에 대해서는 알 수 없습니다.\\n\\n**'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "result['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxNF1I2pUzIv",
        "outputId": "9eacc4c3-3bef-43b7-885b-3c77761a1b6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'page': 1, 'source': 'SamsungElectronics_Gumi/datasets/2023년 가을 학술대회  세부안내.pdf'}, page_content='- 2 -\\n  ○ 등록비\\n     \\n구분 정회원 군경/학부생/\\n 전일제 대학원생 비회원\\n사전등록비 270,000원 150,000원 320,000\\n현장등록비 300,000원 180,000원 320,000\\n  ※ 연구소, 또는 기타 기관에서 등록비 지원을 받는 대학원생은 정회원 등록비.(학생 등록비 아님)\\n  ○ 식사 : 온라인 신청기간 10월 4일 ~ 13일까지\\n    \\n구분 조식, 중식(1회 기준) 만찬\\n식사비 5,000원 신청자에 한해 지원\\n(일부학회지원)\\n만찬은 신청한 회원에 한해 지원되며  그 외 식사는 회당 5,000원(25,000원 상당)\\n씩 회원 부담입니다.\\n등록시 식사 신청을 하지 않은 분들은 현장에서 일반 식사비를 지불해야 합니다.\\n가족식사 신청 만찬 2만원 / 26일 중식 1만원  / 조식뷔폐는 가족식권 판매 안함\\n(단, 현금 결제, 카드결제 안됨)\\n  ○ 지정숙박 : 개별 신청 (신청서 다운로드)\\n      \\n25일(수), 26일(목) \\n 더블 : 100,000원  / 트윈 : 110,000원  /  페밀리 트윈 : 120,000원\\n▢ 행사진행 도우미 모집\\n  ○ 모집인원 : 00명 \\n  ○ 신청기간 : 2023. 10. 2.(월)까지. 심사 후 통보\\n  ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392)\\n  ○ 신청서 : 학회 홈페이지 자료실\\n  ○ 인건비 : 300,000원 (숙박, 식사 제공)\\n  ○ 참여일 : 2023. 10. 25.(수) - 27.(금) \\n▢ 학생등록비 지원(선착순 3명)\\n  ○  신청자격 : 발표자(공동발표자) 중 연구과제에서 등록비를 지원받을 수 없는 학부생과 정회  \\n     원 중 전일제 석, 박사 과정생\\n  ○  지원금액 : 등록비 150,000원\\n  ○  신청마감 : 2023. 10. 2.(월)\\n  ○  지원방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392) \\n  ○ 신청서 : 학회 홈페이지 자료실\\n▢ 연구홍보 게재 및 전시부스 신청\\n   ○ 신청마감 : 2023. 10. 2.(월)\\n   ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr,   팩스 042-865-3392)'),\n",
              " Document(metadata={'page': 1, 'source': 'SamsungElectronics_Gumi/datasets/2023년 가을 학술대회  세부안내.pdf'}, page_content='- 2 -\\n  ○ 등록비\\n     \\n구분 정회원 군경/학부생/\\n 전일제 대학원생 비회원\\n사전등록비 270,000원 150,000원 320,000\\n현장등록비 300,000원 180,000원 320,000\\n  ※ 연구소, 또는 기타 기관에서 등록비 지원을 받는 대학원생은 정회원 등록비.(학생 등록비 아님)\\n  ○ 식사 : 온라인 신청기간 10월 4일 ~ 13일까지\\n    \\n구분 조식, 중식(1회 기준) 만찬\\n식사비 5,000원 신청자에 한해 지원\\n(일부학회지원)\\n만찬은 신청한 회원에 한해 지원되며  그 외 식사는 회당 5,000원(25,000원 상당)\\n씩 회원 부담입니다.\\n등록시 식사 신청을 하지 않은 분들은 현장에서 일반 식사비를 지불해야 합니다.\\n가족식사 신청 만찬 2만원 / 26일 중식 1만원  / 조식뷔폐는 가족식권 판매 안함\\n(단, 현금 결제, 카드결제 안됨)\\n  ○ 지정숙박 : 개별 신청 (신청서 다운로드)\\n      \\n25일(수), 26일(목) \\n 더블 : 100,000원  / 트윈 : 110,000원  /  페밀리 트윈 : 120,000원\\n▢ 행사진행 도우미 모집\\n  ○ 모집인원 : 00명 \\n  ○ 신청기간 : 2023. 10. 2.(월)까지. 심사 후 통보\\n  ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392)\\n  ○ 신청서 : 학회 홈페이지 자료실\\n  ○ 인건비 : 300,000원 (숙박, 식사 제공)\\n  ○ 참여일 : 2023. 10. 25.(수) - 27.(금) \\n▢ 학생등록비 지원(선착순 3명)\\n  ○  신청자격 : 발표자(공동발표자) 중 연구과제에서 등록비를 지원받을 수 없는 학부생과 정회  \\n     원 중 전일제 석, 박사 과정생\\n  ○  지원금액 : 등록비 150,000원\\n  ○  신청마감 : 2023. 10. 2.(월)\\n  ○  지원방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr, 팩스 042-865-3392) \\n  ○ 신청서 : 학회 홈페이지 자료실\\n▢ 연구홍보 게재 및 전시부스 신청\\n   ○ 신청마감 : 2023. 10. 2.(월)\\n   ○ 신청방법 : 신청서 작성하여 신청 (이메일: ksss@ksss.or.kr,   팩스 042-865-3392)')]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "result['source_documents']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSOqIBzXU6f_",
        "outputId": "4539255b-854b-4af4-afcb-75d508299606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "내용 : - 2 -   ○ 등록비       구분 정회원 군경/학부생/  전일제 대학원생 비회원 사전등록비 270,000원 150,000원 320,000 현장등록비 300,000원 180,\n",
            "파일 : SamsungElectronics_Gumi/datasets/2023년 가을 학술대회  세부안내.pdf\n",
            "페이지 : 1\n",
            "내용 : - 2 -   ○ 등록비       구분 정회원 군경/학부생/  전일제 대학원생 비회원 사전등록비 270,000원 150,000원 320,000 현장등록비 300,000원 180,\n",
            "파일 : SamsungElectronics_Gumi/datasets/2023년 가을 학술대회  세부안내.pdf\n",
            "페이지 : 1\n"
          ]
        }
      ],
      "source": [
        "for doc in result['source_documents']:\n",
        "    print('내용 : ' + doc.page_content[0:100].replace('\\n', ' '))\n",
        "    print('파일 : ' + doc.metadata['source'])\n",
        "    print('페이지 : ' + str(doc.metadata['page']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHPK_8ZWHCRb",
        "outputId": "7f2a329b-300d-4a6d-d8a2-80d7a0484fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.6.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.5)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.3 (from gradio)\n",
            "  Downloading gradio_client-1.4.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.3->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.3->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.6.0-py3-none-any.whl (57.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, safehttpx, gradio-client, gradio\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 14.1\n",
            "    Uninstalling websockets-14.1:\n",
            "      Successfully uninstalled websockets-14.1\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 ffmpy-0.4.0 gradio-5.6.0 gradio-client-1.4.3 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.8.0 safehttpx-0.1.1 semantic-version-2.10.0 tomlkit-0.12.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio # 그라디오 라이브러리를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "oiK40JG5hKky"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "Yl_SXA37i4p5",
        "outputId": "0f37e4eb-a268-4101-ab2d-1b763b192a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:225: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://673dfb5c7e75bce8f6.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://673dfb5c7e75bce8f6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://673dfb5c7e75bce8f6.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "def respond(message, chat_history):  # 채팅봇의 응답을 처리하는 함수를 정의합니다.\n",
        "\n",
        "    result = chain(message)\n",
        "\n",
        "    bot_message = result['answer']\n",
        "\n",
        "    for i, doc in enumerate(result['source_documents']):\n",
        "        bot_message += '[' + str(i+1) + '] ' + doc.metadata['source'] + '(' + str(doc.metadata['page']) + ') '\n",
        "\n",
        "    chat_history.append((message, bot_message))  # 채팅 기록에 사용자의 메시지와 봇의 응답을 추가합니다.\n",
        "\n",
        "    return \"\", chat_history  # 수정된 채팅 기록을 반환합니다.\n",
        "\n",
        "with gr.Blocks() as demo:  # gr.Blocks()를 사용하여 인터페이스를 생성합니다.\n",
        "    chatbot = gr.Chatbot(label=\"채팅창\")  # '채팅창'이라는 레이블을 가진 채팅봇 컴포넌트를 생성합니다.\n",
        "    msg = gr.Textbox(label=\"입력\")  # '입력'이라는 레이블을 가진 텍스트박스를 생성합니다.\n",
        "    clear = gr.Button(\"초기화\")  # '초기화'라는 레이블을 가진 버튼을 생성합니다.\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])  # 텍스트박스에 메시지를 입력하고 제출하면 respond 함수가 호출되도록 합니다.\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)  # '초기화' 버튼을 클릭하면 채팅 기록을 초기화합니다.\n",
        "\n",
        "demo.launch(debug=True)  # 인터페이스를 실행합니다. 실행하면 사용자는 '입력' 텍스트박스에 메시지를 작성하고 제출할 수 있으며, '초기화' 버튼을 통해 채팅 기록을 초기화 할 수 있습니다."
      ]
    }
  ]
}